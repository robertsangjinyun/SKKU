---
title: "House Pricing"

output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##첫번째 접근법

  설명변수 전부를 넣고 *osl_step_all_possible()* 를 통해서 Mallow's CP가 작은 몇개의 모델 선정한다.다음 train data에서 30% 추출한 test data로 prediction 했을 때 가장 작은 MSE를 가지는 모델을 최종 모델로 선정하고 실제 test data를 통해 prediction을 한다. 


##첫번쨰 접근법의 문제
 
  1.*osl_step_all_possible()*를 하기에는 설명변수가 너무 많아서 실제로 *용량           부족*으로 함수가 돌아가지 않는다.
  2. Train data에서 30% 추출하면서 남은 70%의 train data에 factor 변수의 *level 
    소실*.


##두번째 접근법
  
  이번에는 *osl_step_backward_p()*를 통해서 변수 하나씩을 제외하면서 최적의 모델을 선정하고 train data는 따로 생성하지 않는다.



##두번쨰 접근법의 문제
  
  1. *Over-fitting* 문제의 가능성
  2. 실제 test data에 "NA" 데이터들이 포함되어 있어서 적합한 모델을 통한 추정값이     "NA"가 나온다. Submission rule에서 모든 열에 대한 추정값을 원하기 때문에 문제     이다. 


##마지막 접근법
 
  1. 실제 test data에서 "NA"를 포함하지는 않는 열만 추출한다.
  2. 추출된 열의 설명변수만을 통해서 osl_step_backward_p를 통해 모델선정



##마지막 접근법의 문제
 
  1. 실제 test data만을 위한 어거지 모델이며 다른 test data가 주어지면 무용지물이     될 가능성이 있다.
  
```{r}
install.packages("tidyverse")
install.packages("olsrr")
library(dplyr)
library(olsrr)
library(magrittr)
```

#데이터 다운 및 NA 확인

```{r}
train = read.csv("train.csv")
test = read.csv("test.csv")
summary(test)
```
NA 데이터들이 확인된다.


#NA를 포함하는 열을 제외

```{r}
test2 = test %>%
  select_if(~ !any(is.na(.)))
  glimpse(test2)
```

#위에 모든 변수를 설명변수로 하는 lm 적합

```{r}
fit = lm(SalePrice ~ MSSubClass + LotArea + Street + LotShape + LandContour + LotConfig +    
              LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual +  
              OverallCond + YearBuilt + YearRemodAdd +  RoofStyle + RoofMatl + ExterQual + ExterCond +    
              Foundation + Heating + HeatingQC + CentralAir + Electrical + X1stFlrSF + X2ndFlrSF +    
              LowQualFinSF + FullBath + HalfBath + BedroomAbvGr +  KitchenAbvGr + TotRmsAbvGrd + 
              Fireplaces + PavedDrive  + WoodDeckSF + OpenPorchSF + EnclosedPorch + X3SsnPorch + ScreenPorch +  
              PoolArea + MiscVal + MoSold + YrSold + SaleCondition, train)
```

# backward 방식으로 AIC 기준으로 모델 선택

```{r}
k = ols_step_backward_aic(fit)
fit2 = k$model
summary(fit2)
```

*유의하지 않는 변수*들이 보이나 prediction이 목적이기에 제거하지 않겠다.



#제거된 변수들

```{r}
k$predictors
```





#Residual 확인


```{r}
plot(fit2$fitted.values, fit2$residuals)
```

분산이 일정해 보이지 않기에 SalePrice에 log를 취하겠다. 

```{r}

fit3 = lm(log(SalePrice) ~  LotArea + Street +  LandContour +     
              LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual +  
              OverallCond + YearBuilt +  RoofStyle + RoofMatl + ExterQual +    
              Foundation +  Electrical + X1stFlrSF + X2ndFlrSF +    
              LowQualFinSF +  BedroomAbvGr +  KitchenAbvGr + 
              Fireplaces +  WoodDeckSF + ScreenPorch +  
              PoolArea +  MoSold +  SaleCondition, train)

summary(fit3)

```

#Residual 확인

```{r}
plot(fit3$fitted.values,fit3$residuals)
```
분산들이 비교적 안정화되었다. 





# Fit3 모델로 test 데이터 예측
```{r}

exp(predict(fit3,test))

```

#Test 데이터에 SalePrice 만들기 

```{r}
test %<>% mutate(Saleprice = exp(predict(fit3,test)))
glimpse(test)
```
SalePrice열 확인